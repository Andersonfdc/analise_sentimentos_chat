import streamlit as st
import os
import gensim
import nltk
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from keras.models import Sequential
from keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional
from nltk.sentiment import SentimentIntensityAnalyzer
from gensim.models import Word2Vec
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from langdetect import detect
from deep_translator import GoogleTranslator
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import pandas as pd
from langdetect import detect
from textblob import TextBlob
from transformers import pipeline, Conversation
from tensorflow.keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import LabelEncoder
from keras.callbacks import Callback
import time
import random

st.set_page_config(
page_title="ChatBot", 
page_icon="	:robot_face:",
)
st.title("An√°lise de sentimentos - chatbot")

nltk.download('punkt', quiet=True)
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('vader_lexicon', quiet=True)
nltk.download('nps_chat', quiet=True)
nltk.download('averaged_perceptron_tagger', quiet=True)

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

sia = SentimentIntensityAnalyzer()
stop_words = set(stopwords.words("portuguese"))

# Inicializa√ß√£o de vari√°veis na sess√£o
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False
if 'last_sentiment' not in st.session_state:
    st.session_state.last_sentiment = ""
if 'sentiment_scores' not in st.session_state:
    st.session_state.sentiment_scores = []
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'tokenizer' not in st.session_state:
    st.session_state.tokenizer = Tokenizer()

st.info("‚ö†Ô∏è O c√≥digo ainda precisa de melhorias e ajustes. üß† Trabalhando para aprimorar todas as funcionalidades.")
st.info("üìä A funcionalidade de an√°lise de sentimento (√∫ltimo gr√°fico √† esquerda, aparece ao enviar uma mensagem) est√° operando com certa imprecis√£o e necessita de melhorias...")

with st.expander("Detalhes do Modelo"):
    st.write("""
    Este c√≥digo implementa um chatbot inteligente para an√°lise de sentimentos e detec√ß√£o de inten√ß√µes usando Streamlit. O chatbot utiliza t√©cnicas de Processamento de Linguagem Natural (PLN), incluindo:
    
    - **An√°lise de Sentimento**: Utiliza um modelo LSTM treinado com dados de sentimento (arquivo `tw_pt.csv`) para classificar o sentimento das mensagens do usu√°rio. Al√©m disso, integra o `TextBlob` para uma an√°lise complementar de polaridade.
    
    - **Detec√ß√£o de Inten√ß√µes**: Um modelo LSTM bidirecional √© treinado com embeddings do Word2Vec para detectar inten√ß√µes em mensagens de usu√°rios. O modelo √© capaz de identificar inten√ß√µes como "sauda√ß√£o", "ajuda", "despedida", entre outras, com base em um conjunto de dados do `nps_chat`.
    
    - **Pr√©-processamento de Texto**: Implementa t√©cnicas de pr√©-processamento, incluindo tokeniza√ß√£o, remo√ß√£o de stopwords, e normaliza√ß√£o de texto para garantir que as entradas sejam adequadas para os modelos.
    
    - **Tradu√ß√£o Autom√°tica**: Detecta automaticamente o idioma da mensagem do usu√°rio e a traduz para o portugu√™s, garantindo compatibilidade com os modelos treinados.
    
    - **Hist√≥rico de Conversa**: Mant√©m um hist√≥rico das intera√ß√µes do usu√°rio, permitindo respostas contextuais e uma an√°lise cont√≠nua do sentimento ao longo da conversa.
    
    - **Pipeline de Classifica√ß√£o**: Al√©m do modelo LSTM, utiliza um classificador Naive Bayes baseado em TF-IDF para an√°lise complementar de inten√ß√µes.

    - **Interface Interativa**: A interface do chatbot √© constru√≠da com Streamlit, permitindo uma intera√ß√£o fluida e amig√°vel com o usu√°rio. O hist√≥rico de conversas √© exibido em tempo real, e o usu√°rio pode limpar o hist√≥rico a qualquer momento.
    
    - **Modelo de Conversa√ß√£o**: Em casos onde a resposta gerada pelo modelo de inten√ß√£o √© muito gen√©rica, o chatbot utiliza um modelo de conversa√ß√£o baseado no DialoGPT para gerar respostas mais contextualizadas.
    
    - **Melhorias Futuras**: O c√≥digo est√° em constante evolu√ß√£o, com planos para melhorar a precis√£o da an√°lise de sentimentos, adicionar mais inten√ß√µes e integrar modelos de linguagem mais avan√ßados, como o GPT-4.
    """)

def preprocess_text(text):
    tokens = word_tokenize(text.lower())
    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]
    return " ".join(tokens)

##############################################
# MODELO DE INTEN√á√ÉO (dados do nps_chat)
##############################################

@st.cache_data
def load_intent_data():
    posts = nltk.corpus.nps_chat.xml_posts()
    data = [(post.text, post.get("class")) for post in posts]
    intent_data = pd.DataFrame(data, columns=["text", "intent"])
    intent_data['text'] = intent_data['text'].apply(preprocess_text)
    return intent_data

intent_data = load_intent_data()
X_train, X_test, y_train, y_test = train_test_split(intent_data['text'], intent_data['intent'], test_size=0.1, random_state=42)

label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

@st.cache_data
def train_word2vec(X_train):
    sentences = [text.split() for text in X_train]
    word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)
    return word2vec_model

word2vec_model = train_word2vec(X_train)

def create_embedding_matrix(word2vec_model, tokenizer, vocab_size, embedding_dim):
    embedding_matrix = np.zeros((vocab_size, embedding_dim))
    for word, i in tokenizer.word_index.items():
        if word in word2vec_model.wv:
            embedding_matrix[i] = word2vec_model.wv[word]
    return embedding_matrix

# Tokeniza√ß√£o e prepara√ß√£o dos dados para o modelo de inten√ß√£o
if 'tokenizer' not in st.session_state:
    st.session_state.tokenizer.fit_on_texts(X_train)
vocab_size = len(st.session_state.tokenizer.word_index) + 1
embedding_dim = 100  # Dimens√£o dos embeddings do Word2Vec

X_train_seq = st.session_state.tokenizer.texts_to_sequences(X_train)
X_test_seq = st.session_state.tokenizer.texts_to_sequences(X_test)

max_length = 100  # Comprimento m√°ximo das sequ√™ncias
X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')
X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')

embedding_matrix = create_embedding_matrix(word2vec_model, st.session_state.tokenizer, vocab_size, embedding_dim)

@st.cache_resource
def create_intent_model(embedding_matrix, vocab_size, embedding_dim, max_length):
    model = Sequential([
        Embedding(
            input_dim=vocab_size, 
            output_dim=embedding_dim, 
            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix), 
            input_shape=(max_length,),
            trainable=True
        ),
        Bidirectional(LSTM(128, return_sequences=True)),
        Dropout(0.3),
        Bidirectional(LSTM(64)),
        Dense(32, activation='relu'),
        Dense(len(label_encoder.classes_), activation='softmax')
    ])
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

if 'intent_model' not in st.session_state:
    st.session_state.intent_model = create_intent_model(embedding_matrix, vocab_size, embedding_dim, max_length)
    
# Callback para visualiza√ß√£o do progresso do treinamento
class ProgressBarCallback(Callback):
    def __init__(self, total_epochs):
        self.total_epochs = total_epochs
        self.progress_bar = st.progress(0)
        self.status_text = st.empty()

    def on_epoch_end(self, epoch, logs=None):
        progress = (epoch + 1) / self.total_epochs
        self.progress_bar.progress(progress)
        self.status_text.text(f"Treinamento do modelo: {epoch + 1}/{self.total_epochs} √©pocas conclu√≠das.")

# Treinamento do modelo de inten√ß√£o
if not st.session_state.model_trained:
    epochs = 10
    progress_callback = ProgressBarCallback(total_epochs=epochs)
    with st.spinner("Treinando modelo de inten√ß√£o..."):
        st.session_state.intent_model.fit(
            X_train_pad,
            y_train_encoded,
            epochs=epochs,
            batch_size=32,
            validation_split=0.1,
            callbacks=[progress_callback],
            verbose=0
        )
    if os.path.exists("modelo.weights.h5"):
        os.remove("modelo.weights.h5")
    st.session_state.model_trained = True
    st.session_state.intent_model.save_weights("modelo.weights.h5")

if os.path.exists("modelo.weights.h5"):
    st.session_state.intent_model = create_intent_model(embedding_matrix, vocab_size, embedding_dim, max_length)
    st.session_state.intent_model.load_weights("modelo.weights.h5")

# Gerar previs√µes para m√©tricas
y_pred = st.session_state.intent_model.predict(X_test_pad)
y_pred_classes = np.argmax(y_pred, axis=1)
y_pred_labels = label_encoder.inverse_transform(y_pred_classes)

##############################################
# MODELO DE SENTIMENTO (dados do tw_pt.csv)
##############################################

@st.cache_data
def load_tw_data():
    df = pd.read_csv("tw_pt.csv")
    df['Text'] = df['Text'].apply(preprocess_text)
    return df

tw_data = load_tw_data()
X_tw = tw_data['Text']
y_tw = tw_data['Classificacao']

label_encoder_tw = LabelEncoder()
y_tw_encoded = label_encoder_tw.fit_transform(y_tw)

if 'tokenizer_tw' not in st.session_state:
    st.session_state.tokenizer_tw = Tokenizer()
    st.session_state.tokenizer_tw.fit_on_texts(X_tw)
vocab_size_tw = len(st.session_state.tokenizer_tw.word_index) + 1
max_length_tw = 100
X_tw_seq = st.session_state.tokenizer_tw.texts_to_sequences(X_tw)
X_tw_pad = pad_sequences(X_tw_seq, maxlen=max_length_tw, padding='post')

def create_tw_sentiment_model(vocab_size, embedding_dim, max_length, num_classes):
    model = Sequential([
        Embedding(input_dim=vocab_size, output_dim=embedding_dim),  # Removido input_length
        LSTM(128, return_sequences=True),
        Dropout(0.3),
        LSTM(64),
        Dense(32, activation='relu'),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

if 'sentiment_model_tw' not in st.session_state:
    num_classes_tw = len(label_encoder_tw.classes_)
    st.session_state.sentiment_model_tw = create_tw_sentiment_model(vocab_size_tw, embedding_dim, max_length_tw, num_classes_tw)
    epochs_tw = 5
    progress_callback_tw = ProgressBarCallback(total_epochs=epochs_tw)
    with st.spinner("Treinando modelo de sentimento..."):
        st.session_state.sentiment_model_tw.fit(
            X_tw_pad, 
            y_tw_encoded, 
            epochs=epochs_tw, 
            batch_size=32, 
            validation_split=0.1, 
            callbacks=[progress_callback_tw],
            verbose=0
        )
    st.session_state.sentiment_model_tw.save_weights("sentiment_model_tw.weights.h5")

if os.path.exists("sentiment_model_tw.weights.h5"):
    st.session_state.sentiment_model_tw = create_tw_sentiment_model(vocab_size_tw, embedding_dim, max_length_tw, len(label_encoder_tw.classes_))
    st.session_state.sentiment_model_tw.build(input_shape=(None, max_length_tw))
    st.session_state.sentiment_model_tw.load_weights("sentiment_model_tw.weights.h5")

def get_sentiment_tw(text):
    """Utiliza o modelo de sentimento treinado com tw_pt.csv para classificar o texto."""
    processed = preprocess_text(text)
    seq = st.session_state.tokenizer_tw.texts_to_sequences([processed])
    pad_seq = pad_sequences(seq, maxlen=max_length_tw, padding='post')
    pred = st.session_state.sentiment_model_tw.predict(pad_seq)
    label = label_encoder_tw.inverse_transform([np.argmax(pred, axis=1)[0]])[0]
    return label

##############################################
# CHATBOT RESPONSE
##############################################

def detect_and_translate(text, target_lang='pt'):
    try:
        detected_lang = detect(text)
    except Exception as e:
        detected_lang = target_lang
    translated_text = GoogleTranslator(source=detected_lang, target=target_lang).translate(text) if detected_lang != target_lang else text
    return translated_text

# Inicializa a pipeline conversacional
if 'conversational_pipeline' not in st.session_state:
    st.session_state.conversational_pipeline = pipeline(
        "conversational", 
        model="microsoft/DialoGPT-medium", 
        framework="pt" 
    )

def chatbot_response(user_input):
    
    translated_input = detect_and_translate(user_input)
    
    
    blob = TextBlob(translated_input)
    polarity = blob.sentiment.polarity  # valor entre -1 (muito negativo) e 1 (muito positivo)
    if polarity < -0.2:
        sentiment_label = "negativo"
    elif polarity > 0.2:
        sentiment_label = "positivo"
    else:
        sentiment_label = "neutro"
    
    # Pr√©-processamento e prepara√ß√£o para previs√£o de inten√ß√£o
    processed_input = preprocess_text(translated_input)
    input_seq = st.session_state.tokenizer.texts_to_sequences([processed_input])
    input_pad = pad_sequences(input_seq, maxlen=max_length, padding='post')
    
    # Previs√£o da inten√ß√£o com o modelo LSTM treinado
    with st.spinner("Processando inten√ß√£o..."):
        intent_pred = st.session_state.intent_model.predict(input_pad)
    intent_class = np.argmax(intent_pred, axis=1)
    intent_label = label_encoder.inverse_transform(intent_class)[0]
    
    # Inten√ß√£o com regras baseadas em palavras-chave
    input_lower = translated_input.lower()
    if any(s in input_lower for s in ["ol√°", "oi", "bom dia", "boa tarde", "boa noite"]):
        intent_label = "sauda√ß√£o"
    elif "nome" in input_lower:
        intent_label = "nome"
    elif any(s in input_lower for s in ["ajuda", "suporte", "preciso de ajuda"]):
        intent_label = "ajuda"
    elif any(s in input_lower for s in ["tudo bem", "como vai", "como est√°"]):
        intent_label = "sauda√ß√£o"
    
    # Defini√ß√£o de templates de resposta para cada inten√ß√£o
    response_templates = {
        "sauda√ß√£o": ["Ol√°! Como posso ajudar?", "Oi! Tudo bem?", "Bom dia!", "Oi! Como vai?"],
        "ajuda": ["Claro! Qual sua d√∫vida?", "Estou aqui para ajudar!", "Como posso ser √∫til hoje?"],
        "documento": ["Envie o documento para an√°lise!", "Vou processar seu documento!", "Por favor, envie o documento que deseja analisar."],
        "raiva": ["Sinto muito! Como posso resolver sua insatisfa√ß√£o?", "Entendo sua frustra√ß√£o, vamos resolver isso juntos.", "Pe√ßo desculpas pelo ocorrido. Como posso ajudar?"],
        "elogio": ["Muito obrigado! Fico feliz em ajudar!", "Agrade√ßo pelo feedback positivo!", "Fico feliz que esteja satisfeito!"],
        "tristeza": ["Sinto muito que voc√™ esteja se sentindo assim. Posso ajudar em algo?", "Lamento ouvir isso. Estou aqui para o que precisar.", "Sinto muito. Conte comigo para o que precisar."],
        "nome": ["Meu nome √© Chatbot. Como posso ajudar voc√™ hoje?", "Eu sou o Chatbot, seu assistente virtual.", "Pode me chamar de Chatbot. Como posso ajudar?"],
        "felicidade": ["Que bom que voc√™ est√° feliz! Como posso ajudar?", "Fico feliz em saber que voc√™ est√° contente!", "√â √≥timo ver voc√™ feliz! O que posso fazer por voc√™?"],
        "despedida": ["At√© logo! Espero ter ajudado.", "Tchau! Volte sempre que precisar.", "At√© mais! Estou aqui se precisar."],
        "d√∫vida": ["Pode me explicar melhor?", "N√£o entendi completamente. Pode reformular?", "Poderia detalhar um pouco mais?"]
    }
    
    # Sele√ß√£o da resposta baseada na inten√ß√£o, sentimento e contexto
    if intent_label in response_templates:
        if st.session_state.chat_history:
            if sentiment_label in ["negativo", "raiva", "triste"]:
                response = "Percebo que voc√™ est√° passando por um momento dif√≠cil. Estou aqui para ajudar. Pode me contar mais?"
            elif sentiment_label in ["positivo", "felicidade", "elogio"]:
                response = random.choice(response_templates.get("felicidade", ["Que bom!"]))
            else:
                response = random.choice(response_templates[intent_label])
        else:
            response = random.choice(response_templates[intent_label])
    else:
        response = "Poderia me explicar melhor? Quero entender para poder ajudar!"
    
    # Fallback com modelo de conversa√ß√£o se a resposta for muito gen√©rica
    if response.startswith("Poderia me explicar melhor"):
        with st.spinner("Gerando resposta..."):
            conversation = Conversation(translated_input)
            result = st.session_state.conversational_pipeline(conversation)
            # Usa a √∫ltima resposta gerada pelo modelo de conversa√ß√£o
            response = result.generated_responses[-1]
    
    return response, sentiment_label
##############################################
# INTERFACE DO CHAT
##############################################

st.subheader("Chat com Chatbot Inteligente")
chat_container = st.container()

with chat_container:
    chat_placeholder = st.empty()
    
    # Renderizando mensagens anteriores
    for sender, message in st.session_state.chat_history:
        if sender == "Voc√™":
            st.chat_message("user").markdown(f"<strong>Voc√™:</strong> {message}", unsafe_allow_html=True)
        else:
            with st.chat_message("assistant"):
                st.markdown(f"<strong>Chatbot:</strong> {message}", unsafe_allow_html=True)

user_input = st.chat_input("Digite sua mensagem")
if user_input:
    with st.spinner("Processando sua mensagem..."):
        response, sentiment = chatbot_response(user_input)
        
    # Adicionando a mensagem do usu√°rio e a resposta do chatbot ao hist√≥rico
    st.session_state.chat_history.append(("Voc√™", user_input))
    st.session_state.chat_history.append(("Chatbot", response))
    st.session_state.last_sentiment = sentiment
    
    # Re-renderizando as mensagens
    for sender, message in st.session_state.chat_history:
        if sender == "Voc√™":
            st.chat_message("user").markdown(f"<strong>Voc√™:</strong> {message}", unsafe_allow_html=True)
        else:
            with st.chat_message("assistant"):
                st.markdown(f"<strong>Chatbot:</strong> {message}", unsafe_allow_html=True)
    
 
    st.rerun()

##############################################
# SIDEBAR COM M√âTRICAS E AN√ÅLISES
##############################################

st.sidebar.header("An√°lises e M√©tricas")
st.sidebar.subheader("Desempenho do Modelo de Inten√ß√£o")
st.sidebar.write("Accuracy:", accuracy_score(y_test, y_pred_labels))
st.sidebar.write("Classification Report:")
st.sidebar.text(classification_report(y_test, y_pred_labels))

st.sidebar.subheader("Sentimento da √öltima Mensagem")
st.sidebar.write(f"{st.session_state.last_sentiment}")

st.sidebar.subheader("Evolu√ß√£o do Sentimento")
# Extrai os sentimentos das mensagens do usu√°rio utilizando o modelo tw_pt
sentiments = [get_sentiment_tw(msg[1]) for msg in st.session_state.chat_history if msg[0] == "Voc√™"]
if sentiments:
    # Converte os r√≥tulos para pontua√ß√µes para plot (ex.: Positivo: 1, Neutro: 0, Negativo: -1)
    sentiment_scores = [1 if s.lower() in ["positivo", "felicidade", "elogio"] else -1 if s.lower() in ["negativo", "raiva", "triste"] else 0 for s in sentiments]
    fig, ax = plt.subplots()
    sns.lineplot(x=range(len(sentiment_scores)), y=sentiment_scores, ax=ax, marker='o')
    ax.set_title("Evolu√ß√£o do Sentimento")
    ax.set_xlabel("Mensagens")
    ax.set_ylabel("Pontua√ß√£o de Sentimento")
    st.sidebar.pyplot(fig)

if st.sidebar.button("Limpar Hist√≥rico do Chat"):
    st.session_state.chat_history = []
    st.rerun()
